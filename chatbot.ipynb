{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8Jvj6+MLJNNzcrRXcXKKl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fehnicchio/IA/blob/main/chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdN2E_f6rnIx",
        "outputId": "94a126f1-c85b-458b-e5f6-e42b002b3ead"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.8/677.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY=\"Your_API_Key\"\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "3HBuSWKNB0Zi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "CnhWE31oCiWk",
        "outputId": "11000ce5-9aac-4725-c363-11f5e8187ec1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  generation_Config = {\n",
        "      \"candidate_count\": 1,\n",
        "      \"temperature\": 0.5,\n",
        "  }"
      ],
      "metadata": {
        "id": "sac1HRIcE_4f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = {\n",
        "    \"HARASSMENT\": \"BLOCK_NONE\",\n",
        "    \"HATE\": \"BLOCK_NONE\",\n",
        "    \"SEXUAL\": \"BLOCK_NONE\",\n",
        "    \"DANGEROUS\": \"BLOCK_NONE\"\n",
        "}"
      ],
      "metadata": {
        "id": "ZJqe0dW9FuI_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro-latest\",generation_config=generation_Config, safety_settings=safety_settings)"
      ],
      "metadata": {
        "id": "NiacRu9LHqKp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Vamos falar sobre deep learning\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812
        },
        "id": "hXtNN0h4I3U3",
        "outputId": "e5487e8f-fd6d-4234-e7f9-fd30e6d9a6b9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**O que é Deep Learning?**\n",
            "\n",
            "Deep learning é um subcampo da inteligência artificial (IA) que usa redes neurais artificiais com várias camadas para aprender representações de dados de alto nível. Essas redes são treinadas em grandes conjuntos de dados e podem identificar padrões complexos e fazer previsões precisas.\n",
            "\n",
            "**Como funciona o Deep Learning?**\n",
            "\n",
            "As redes neurais de deep learning são inspiradas no cérebro humano. Elas consistem em camadas de nós chamados neurônios artificiais, que são conectados entre si. Cada neurônio recebe dados de entrada, aplica uma função de ativação e produz uma saída.\n",
            "\n",
            "As camadas são empilhadas umas sobre as outras, criando uma hierarquia de representações. As camadas iniciais aprendem recursos de baixo nível, como bordas e cores, enquanto as camadas posteriores aprendem recursos de alto nível, como objetos e rostos.\n",
            "\n",
            "**Aplicações do Deep Learning**\n",
            "\n",
            "O deep learning tem uma ampla gama de aplicações, incluindo:\n",
            "\n",
            "* **Visão computacional:** Reconhecimento de imagem, detecção de objetos, segmentação de imagem\n",
            "* **Processamento de linguagem natural:** Tradução de idiomas, geração de texto, reconhecimento de fala\n",
            "* **Aprendizado de reforço:** Jogos, robótica, otimização\n",
            "* **Ciência de dados:** Previsão, classificação, detecção de anomalias\n",
            "* **Cuidados de saúde:** Diagnóstico, tratamento, descoberta de medicamentos\n",
            "\n",
            "**Vantagens do Deep Learning**\n",
            "\n",
            "* **Alto desempenho:** As redes neurais de deep learning podem alcançar desempenho de ponta em muitas tarefas.\n",
            "* **Aprendizado de ponta a ponta:** Elas podem aprender diretamente a partir de dados brutos, sem a necessidade de recursos projetados manualmente.\n",
            "* **Representações hierárquicas:** Elas aprendem representações de dados de alto nível que podem ser usadas para diversas tarefas.\n",
            "* **Escalabilidade:** Elas podem ser treinadas em conjuntos de dados massivos, o que leva a melhor desempenho.\n",
            "\n",
            "**Desafios do Deep Learning**\n",
            "\n",
            "* **Necessidade de grandes conjuntos de dados:** As redes neurais de deep learning requerem grandes quantidades de dados para treinamento.\n",
            "* **Tempo e recursos computacionais:** O treinamento de modelos de deep learning pode ser demorado e exigir hardware poderoso.\n",
            "* **Interpretabilidade:** Pode ser difícil entender como as redes neurais de deep learning tomam decisões.\n",
            "* **Viés:** Os modelos de deep learning podem ser tendenciosos se forem treinados em dados tendenciosos.\n",
            "\n",
            "**Tendências e Pesquisas Futuras**\n",
            "\n",
            "A pesquisa em deep learning está em constante evolução, com novas tendências e avanços emergindo regularmente. Algumas áreas ativas de pesquisa incluem:\n",
            "\n",
            "* **Aprendizado de representação:** Desenvolver novas técnicas para aprender representações de dados mais eficazes.\n",
            "* **Aprendizado autossupervisionado:** Reduzir a dependência de dados rotulados usando técnicas de autossupervisão.\n",
            "* **Aprendizado de transferência:** Transferir conhecimento de tarefas relacionadas para melhorar o desempenho em novas tarefas.\n",
            "* **IA explicável:** Desenvolver técnicas para tornar os modelos de deep learning mais interpretáveis e confiáveis.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "XlkYJNS9WcUY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = input(\"Aguardando o prompt: \")\n",
        "\n",
        "while prompt != \"fim\":\n",
        "  response = chat.send_message(prompt)\n",
        "  print(\"Resposta: \", response.text, \"\\n\")\n",
        "  prompt = input(\"Aguardando o prompt: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "SzInimQ8XOGo",
        "outputId": "a8746af5-5f07-48f6-e417-395edfb21ccd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aguardando o prompt: Qual a capital do Brasil?\n",
            "Resposta:  Brasília \n",
            "\n",
            "Aguardando o prompt: Quala  comida tipica desse país?\n",
            "Resposta:  Feijoada \n",
            "\n",
            "Aguardando o prompt: meu irmão nasceu nessa cidad3e, qual a nacionalidade dele?\n",
            "Resposta:  Brasileira \n",
            "\n",
            "Aguardando o prompt: fim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Melhorando a vizualização\n",
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "#Imprimindo historico\n",
        "for message in chat.history:\n",
        "  display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))\n",
        "  print('-------------------------------')"
      ],
      "metadata": {
        "id": "H-iTUi-vZVNh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}